{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goals / steps of this project are the following:\n",
    "\n",
    "- Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "- Apply a distortion correction to raw images.\n",
    "- Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "- Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "- Detect lane pixels and fit to find the lane boundary.\n",
    "- Determine the curvature of the lane and vehicle position with respect to center.\n",
    "- Warp the detected lane boundaries back onto the original image.\n",
    "- Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "%matplotlib inline\n",
    "\n",
    "def camera_calibration(link='camera_cal/calibration*.jpg'):\n",
    "    objp = np.zeros((6*9,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "    objpoints = [] # 3d points in real world space\n",
    "    imgpoints = [] # 2d points in image plane.\n",
    "    images = glob.glob(link)\n",
    "    for fname in images:\n",
    "        img = cv2.imread(fname)\n",
    "        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (9,6),None)\n",
    "        if ret == True:\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "            img = cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "    return objpoints, imgpoints\n",
    "\n",
    "def cal_undistort(img, objpoints, imgpoints):\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img.shape[1:], None, None)\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    return undist\n",
    "\n",
    "def draw_lines(img, lines, color=[255, 0, 0], thickness=2):\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            cv2.line(img, (x1, y1), (x2, y2), color, thickness)\n",
    "            \n",
    "def weighted_img(img, initial_img, α=0.8, β=1., γ=0.):\n",
    "    return cv2.addWeighted(initial_img, α, img, β, γ)\n",
    "            \n",
    "def advance_procces(image):\n",
    "    (b, g, r) = cv2.split(image)\n",
    "    c1 = (b < 120) & (r > 140) & (g > 140)\n",
    "    c2 = (b > 180) & (r > 180) & (g > 180)\n",
    "    binary_1 = np.zeros_like(b)\n",
    "    binary_2 = np.zeros_like(b)\n",
    "    binary_1[c1]=1\n",
    "    binary_2[c2]=1\n",
    "    bitwise_or = cv2.bitwise_or(binary_1, binary_2)\n",
    "    return bitwise_or\n",
    "\n",
    "def hist(img):\n",
    "    bottom_half = img[img.shape[0]//2:,:]\n",
    "    histogram = np.sum(bottom_half, axis=0)\n",
    "    return histogram\n",
    "\n",
    "def measure_curvature_pixels(ploty,left_fit, right_fit,):\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    y_eval = np.max(ploty)\n",
    "    left_curverad = ((1 + (2*left_fit[0]*y_eval + left_fit[1])**2)**1.5) / np.absolute(2*left_fit[0])\n",
    "    right_curverad = ((1 + (2*right_fit[0]*y_eval + right_fit[1])**2)**1.5) / np.absolute(2*right_fit[0])\n",
    "    return left_curverad, right_curverad\n",
    "\n",
    "def car_offset(leftx, rightx, img_shape, xm_per_pix=3.7/800):\n",
    "    mid_imgx = img_shape[1]//2      \n",
    "    car_pos = (leftx[-1] + rightx[-1])/2\n",
    "    offsetx = (mid_imgx - car_pos) * xm_per_pix\n",
    "    return offsetx\n",
    "\n",
    "def annotation(img_lane, combo, leftx, rightx, ploty, left_fit, right_fit):\n",
    "    left_curverad,right_curverad = measure_curvature_pixels(ploty, left_fit, right_fit)\n",
    "    # Display curvature_rad \n",
    "    cv2.putText(img_lane, 'curvature: {:.2f} m'.format(left_curverad), (300, 60), cv2.FONT_HERSHEY_DUPLEX, 1.5, (255,255,255), 5)\n",
    "    #cv2.putText(out_img, 'Right curvature: {:.2f} m'.format(right_curverad), (300, 110), cv2.FONT_HERSHEY_DUPLEX, 1.5, (255,255,255), 5)\n",
    "    # Display car offset\n",
    "    #offset = car_offset(leftx, rightx, img_lane.shape)\n",
    "    #cv2.putText(img_lane, 'Offset w.r.t center: {:.2f} m'.format(offset), (300, 160), cv2.FONT_HERSHEY_DUPLEX, 1.5, (255,255,255), 5)\n",
    "    \n",
    "def draw_lane(img, warp, left_points, right_points, Minv):\n",
    "    # Create an image to draw the lines on\n",
    "    warp_zero = np.zeros_like(warp).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    left_fitx = left_points[0]\n",
    "    right_fitx = right_points[0]\n",
    "    ploty = left_points[1]\n",
    "\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    reverse_warp = cv2.warpPerspective(color_warp, Minv, (img.shape[1], img.shape[0])) \n",
    "    # Combine the result with the original image\n",
    "    return cv2.addWeighted(img, 1, reverse_warp, 0.3, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lane_pixels(binary_warped):\n",
    "    global prev_left_fit  \n",
    "    global prev_right_fit\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "    # Create an output image to draw on and visualize the result\n",
    "    #out_img = np.dstack((binary_warped, binary_warped, binary_warped))\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]//2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "    delta = rightx_base - leftx_base\n",
    "    \n",
    "    # Set height of windows - based on nwindows above and image shape\n",
    "    nonzero_left = binary_warped[:,:midpoint].nonzero()\n",
    "    lefty = np.array(nonzero_left[0])\n",
    "    leftx = np.array(nonzero_left[1])\n",
    "    nonzero_right = binary_warped[:,midpoint:].nonzero()\n",
    "    righty = np.array(nonzero_right[0])\n",
    "    rightx = np.array(nonzero_right[1]) + midpoint\n",
    "    \n",
    "    \n",
    "    if  leftx.size > 3 and rightx.size > 3:\n",
    "        x = np.append(leftx, rightx-delta, axis=0)\n",
    "        y = np.append(lefty, righty, axis=0)\n",
    "        left_fit = np.polyfit(y, x, 2)\n",
    "        right_fit = np.polyfit(y, x, 2)\n",
    "        right_fit[2] = right_fit[2]+delta\n",
    "        \n",
    "        prev_left_fit = left_fit\n",
    "        prev_right_fit = right_fit\n",
    "    else: \n",
    "        left_fit = prev_left_fit\n",
    "        right_fit = prev_right_fit\n",
    "            # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "    #try:\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    #except TypeError:\n",
    "    # Avoids an error if `left_fit` and `right_fit` are still none or incorrect\n",
    "    #    print('The function failed to fit a line!')\n",
    "    #    ret = 'False' \n",
    "    #left_fitx = 1*ploty**2 + 1*ploty\n",
    "    #right_fitx = 1*ploty**2 + 1*ploty\n",
    "    return leftx, lefty, rightx, righty, left_fit, right_fit, left_fitx, right_fitx, ploty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparation step 1: find the objpoints, imgpoints from camera calibration\n",
    "objpoints, imgpoints = camera_calibration(link='camera_cal/calibration*.jpg');\n",
    "# preparation step 2: identify the Perspective Transform matrix M by the given source and destination points\n",
    "src = np.float32(\n",
    "    [[280,  700],  # Bottom left\n",
    "     [595,  460],  # Top left\n",
    "     [725,  460],  # Top right\n",
    "     [1125, 700]]) # Bottom right\n",
    "\n",
    "dst = np.float32(\n",
    "    [[250,  720],  # Bottom left\n",
    "     [250,    0],  # Top left\n",
    "     [1065,   0],  # Top right\n",
    "     [1065, 720]]) # Bottom right\n",
    "M = cv2.getPerspectiveTransform(src, dst)\n",
    "Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "left_fit = np.array([ 2.13935315e-04, -3.77507980e-01,  4.76902175e+02])\n",
    "right_fit = np.array([4.17622148e-04, -4.93848953e-01,  1.11806170e+03])\n",
    "# build the pipeline\n",
    "\n",
    "def pipeline(img):\n",
    "    global prev_left_fit  \n",
    "    global prev_rightx_fit\n",
    "    t=60\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    objpoints, imgpoints = camera_calibration(link='camera_cal/calibration*.jpg');\n",
    "    src = np.float32(\n",
    "        [[280,  700],  # Bottom left\n",
    "         [595,  460],  # Top left\n",
    "         [725,  460],  # Top right\n",
    "         [1125, 700]]) # Bottom right\n",
    "    dst = np.float32(\n",
    "        [[250,  720],  # Bottom left\n",
    "         [250,    0],  # Top left\n",
    "         [1065,   0],  # Top right\n",
    "         [1065, 720]]) # Bottom right\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "#step 1: obatin the undistort image \n",
    "    undistorted = cal_undistort(img, objpoints, imgpoints)\n",
    "#step 2: apply Perspective Transform matrix M to \"bird-view\" \n",
    "    img_size = (undistorted.shape[1], undistorted.shape[0])\n",
    "    warped = cv2.warpPerspective(undistorted, M, img_size)\n",
    "#step 3: color detetion to have robust lane detetion\n",
    "    if np.mean(warped) > 100:\n",
    "        background = np.ones(warped.shape, dtype=\"uint8\") * 20\n",
    "    elif np.mean(warped) > 60:\n",
    "        background = np.ones(warped.shape, dtype=\"uint8\") * 0\n",
    "    else: \n",
    "        background = np.ones(warped.shape, dtype=\"uint8\") * (-20)    \n",
    "    subtracted_image = cv2.subtract(warped, background)\n",
    "    combo = advance_procces(subtracted_image)\n",
    "#step 4: apply the polynomial fit on histogram \n",
    "    leftx, lefty, rightx, righty, left_fit, right_fit, left_fitx, right_fitx, ploty = find_lane_pixels(combo)\n",
    "#step 5 Warp the detected lane boundaries back onto the original image\n",
    "    img_lane = draw_lane(img, combo, (left_fitx, ploty), (right_fitx, ploty), Minv)\n",
    "#step 6 annotate metrics onto the origianl image\n",
    "    annotation(img_lane, combo, leftx, rightx, ploty, left_fit, right_fit)\n",
    "        #return img_lane\n",
    "    return plt.imshow(img_lane)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(3.4.2) /opt/concourse/worker/volumes/live/9523d527-1b9e-48e0-7ed0-a36adde286f0/volume/opencv-suite_1535558719691/work/modules/core/src/arithm.cpp:659: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-1d7020f78c44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mimg_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_img_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test_images/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mimg_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-f7318bafe83d>\u001b[0m in \u001b[0;36mpipeline\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mleftx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlefty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrightx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrighty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_fit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_fit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_fitx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_fitx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mploty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_lane_pixels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;31m#step 5 Warp the detected lane boundaries back onto the original image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mimg_lane\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdraw_lane\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mleft_fitx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mploty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mright_fitx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mploty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMinv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;31m#step 6 annotate metrics onto the origianl image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mannotation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_lane\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleftx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrightx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mploty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_fit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_fit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-0ba607746c9e>\u001b[0m in \u001b[0;36mdraw_lane\u001b[0;34m(img, warp, left_points, right_points, Minv)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0mreverse_warp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarpPerspective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwarp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMinv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;31m# Combine the result with the original image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddWeighted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse_warp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31merror\u001b[0m: OpenCV(3.4.2) /opt/concourse/worker/volumes/live/9523d527-1b9e-48e0-7ed0-a36adde286f0/volume/opencv-suite_1535558719691/work/modules/core/src/arithm.cpp:659: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n"
     ]
    }
   ],
   "source": [
    "test_img_list= os.listdir(\"test_images/\")\n",
    "img_name = test_img_list[2]\n",
    "img = cv2.imread(\"test_images/\" + img_name)\n",
    "pipeline(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_list= os.listdir(\"test_images/\")\n",
    "for i in range(0,len(test_img_list)):\n",
    "    img_name = test_img_list[i]\n",
    "    img = cv2.imread(\"test_images/\" + img_name)\n",
    "    pipeline(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Video "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "import os\n",
    "out_dir = 'test_videos_output'\n",
    "if os.path.exists(out_dir)==0:\n",
    "    os.mkdir(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(3.4.2) /opt/concourse/worker/volumes/live/9523d527-1b9e-48e0-7ed0-a36adde286f0/volume/opencv-suite_1535558719691/work/modules/core/src/arithm.cpp:659: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-a3237d820af2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\").subclip(0,5)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mclip1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVideoFileClip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'project_video.mp4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mwhite_clip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclip1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfl_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# NOTE: this function expects color images!!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'white_clip.write_videofile(white_output, audio=False)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Udacity/lib/python3.5/site-packages/moviepy/video/VideoClip.py\u001b[0m in \u001b[0;36mfl_image\u001b[0;34m(self, image_func, apply_to)\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mapply_to\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m             \u001b[0mapply_to\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mgf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimage_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m     \u001b[0;31m# --------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Udacity/lib/python3.5/site-packages/moviepy/Clip.py\u001b[0m in \u001b[0;36mfl\u001b[0;34m(self, fun, apply_to, keep_duration)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;31m#mf = copy(self.make_frame)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0mnewclip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_make_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkeep_duration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m</anaconda3/envs/Udacity/lib/python3.5/site-packages/decorator.py:decorator-gen-181>\u001b[0m in \u001b[0;36mset_make_frame\u001b[0;34m(self, mf)\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Udacity/lib/python3.5/site-packages/moviepy/decorators.py\u001b[0m in \u001b[0;36moutplace\u001b[0;34m(f, clip, *a, **k)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;34m\"\"\" Applies f(clip.copy(), *a, **k) and returns clip.copy()\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mnewclip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnewclip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Udacity/lib/python3.5/site-packages/moviepy/video/VideoClip.py\u001b[0m in \u001b[0;36mset_make_frame\u001b[0;34m(self, mf)\u001b[0m\n\u001b[1;32m    664\u001b[0m         \"\"\"\n\u001b[1;32m    665\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 666\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moutplace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m</anaconda3/envs/Udacity/lib/python3.5/site-packages/decorator.py:decorator-gen-134>\u001b[0m in \u001b[0;36mget_frame\u001b[0;34m(self, t)\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Udacity/lib/python3.5/site-packages/moviepy/decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(f, *a, **kw)\u001b[0m\n\u001b[1;32m     87\u001b[0m         new_kw = {k: fun(v) if k in varnames else v\n\u001b[1;32m     88\u001b[0m                  for (k,v) in kw.items()}\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Udacity/lib/python3.5/site-packages/moviepy/Clip.py\u001b[0m in \u001b[0;36mget_frame\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_duration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Udacity/lib/python3.5/site-packages/moviepy/Clip.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;31m#mf = copy(self.make_frame)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0mnewclip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_make_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkeep_duration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Udacity/lib/python3.5/site-packages/moviepy/video/VideoClip.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(gf, t)\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mapply_to\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m             \u001b[0mapply_to\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mgf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimage_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m     \u001b[0;31m# --------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-f7318bafe83d>\u001b[0m in \u001b[0;36mpipeline\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mleftx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlefty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrightx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrighty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_fit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_fit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_fitx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_fitx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mploty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_lane_pixels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;31m#step 5 Warp the detected lane boundaries back onto the original image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mimg_lane\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdraw_lane\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mleft_fitx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mploty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mright_fitx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mploty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMinv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;31m#step 6 annotate metrics onto the origianl image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mannotation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_lane\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleftx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrightx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mploty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_fit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_fit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-0ba607746c9e>\u001b[0m in \u001b[0;36mdraw_lane\u001b[0;34m(img, warp, left_points, right_points, Minv)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0mreverse_warp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarpPerspective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwarp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMinv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;31m# Combine the result with the original image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddWeighted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse_warp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31merror\u001b[0m: OpenCV(3.4.2) /opt/concourse/worker/volumes/live/9523d527-1b9e-48e0-7ed0-a36adde286f0/volume/opencv-suite_1535558719691/work/modules/core/src/arithm.cpp:659: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n"
     ]
    }
   ],
   "source": [
    "prev_left_fit  = np.array([ 2.21903007e-04, -2.02707371e-01,  2.72740313e+02])\n",
    "prev_right_fit = np.array([ 2.21903007e-04, -2.02707371e-01,  1.09674031e+03])\n",
    "white_output = './test_videos_output/project_video_annotated.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "#clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\").subclip(0,5)\n",
    "clip1 = VideoFileClip('project_video.mp4').subclip(0,1)\n",
    "white_clip = clip1.fl_image(pipeline) # NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.13935315e-04, -3.77507980e-01,  4.76902175e+02])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_left_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
